{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:19:58.563067400Z",
     "start_time": "2025-06-03T05:19:58.174828500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:16:38.377332400Z",
     "start_time": "2025-06-03T06:16:34.265146600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = date.today().toordinal()\n",
    "\n",
    "DATA_PATH = '../../datasets/train-00000-of-00001.parquet'\n",
    "OUTPUT_PATH = '../../datasets/Processed/Gloss_feat/processed_data.pt'\n",
    "\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(df):\n",
    "    \n",
    "    text_counter = Counter()\n",
    "    gloss_counter = Counter()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        full_text = row[\"text\"]\n",
    "        \n",
    "        gloss = full_text.split(\"[INST]\")[1].split(\"[/INST]\")[0].strip()\n",
    "        gloss_tokens = gloss.split()\n",
    "        gloss_counter.update(gloss_tokens)\n",
    "        \n",
    "        text = full_text.split(\"[/INST]\")[1].replace(\"</s>\", \"\").strip().lower()\n",
    "        text_tokens = text.split()\n",
    "        text_counter.update(text_tokens)\n",
    "        \n",
    "        base_tokens = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "        \n",
    "        text_vocab = {tok: idx for idx, tok in enumerate(base_tokens)}\n",
    "        for tok, _ in text_counter.most_common():\n",
    "            if tok not in text_vocab:\n",
    "                text_vocab[tok] = len(text_vocab)\n",
    "                \n",
    "        gloss_vocab = {tok: idx for idx, tok in enumerate(base_tokens)}\n",
    "        for tok, _ in gloss_counter.most_common():\n",
    "            if tok not in gloss_vocab:\n",
    "                gloss_vocab[tok] = len(gloss_vocab)\n",
    "                \n",
    "        return text_vocab, gloss_vocab\n",
    "\n",
    "def tokenize_and_pad(sequence, vocab, max_len, is_gloss):\n",
    "    if is_gloss:\n",
    "        tokens = sequence.split(\"[INST]\")[1].split(\"[/INST]\")[0].strip().split()\n",
    "    else:\n",
    "        tokens = sequence.split(\"[/INST]\")[1].replace(\"</s>\", \"\").strip().lower().split()\n",
    "    \n",
    "    idxs = [vocab.get(w, vocab[\"<unk>\"]) for w in tokens]\n",
    "    idxs = [vocab[\"<sos>\"]] + idxs + [vocab[\"<eos>\"]]\n",
    "    \n",
    "    if len(idxs) < max_len:\n",
    "        idxs = idxs + [vocab[\"<pad>\"]] * (max_len - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[: max_len - 1] + [vocab[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "\n",
    "text_vocab, gloss_vocab = build_vocabularies(df)\n",
    "print(f\"> Built text_vocab (size: {len(text_vocab)}) and gloss_vocab (size: {len(gloss_vocab)})\")\n",
    "\n",
    "all_text_tensors  = []\n",
    "all_gloss_tensors = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Tokenizing\"):\n",
    "    raw = row[\"text\"]\n",
    "    gloss_tensor = tokenize_and_pad(raw, gloss_vocab, max_len=MAX_SEQ_LEN, is_gloss=True)\n",
    "    text_tensor  = tokenize_and_pad(raw, text_vocab,  max_len=MAX_SEQ_LEN, is_gloss=False)\n",
    "\n",
    "    all_gloss_tensors.append(gloss_tensor.to(device))\n",
    "    all_text_tensors.append(text_tensor.to(device))\n",
    "\n",
    "gloss_matrix = torch.stack(all_gloss_tensors)   # (N, MAX_SEQ_LEN)\n",
    "text_matrix  = torch.stack(all_text_tensors)    # ( N,MAX_SEQ_LEN)\n",
    "\n",
    "save_dict = {\n",
    "    \"text_vocab\": text_vocab,\n",
    "    \"gloss_vocab\": gloss_vocab,\n",
    "    \"inv_gloss\": {v: k for k, v in gloss_vocab.items()},\n",
    "    \"text_matrix\": text_matrix,   # torch.LongTensor\n",
    "    \"gloss_matrix\": gloss_matrix, # torch.LongTensor\n",
    "}\n",
    "torch.save(save_dict, OUTPUT_PATH)\n",
    "print(f\"> Saved processed data to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## txtGlossDataset CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:51.239920300Z",
     "start_time": "2025-06-03T06:21:51.228494300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextGlossDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.text_data = [\"hello world\", \"good morning\"]\n",
    "        self.gloss_data = [[\"HELLO\", \"WORLD\"], [\"GOOD\", \"MORNING\"]]\n",
    "        self.text_vocab = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"hello\":3, \"world\":4, \"good\":5, \"morning\":6}\n",
    "        self.gloss_vocab = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"HELLO\":3, \"WORLD\":4, \"GOOD\":5, \"MORNING\":6}\n",
    "        self.inv_gloss = {v:k for k, v in self.gloss_vocab.items()}\n",
    "\n",
    "    def __len__(self): return len(self.text_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = [self.text_vocab[w] for w in self.text_data[idx].split()]\n",
    "        gloss = [self.gloss_vocab[g] for g in self.gloss_data[idx]]\n",
    "        return torch.tensor(text), torch.tensor(gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGlossDataset2(Dataset):\n",
    "    def __init__(self, parquet_path, max_seq_length=50):\n",
    "        \n",
    "        self.df = pd.read_parquet(parquet_path)\n",
    "        \n",
    "        self.text_vocab = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
    "        self.gloss_vocab = {\"<pad>\":0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\":3}\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        self._build_vocabs()\n",
    "        \n",
    "        self.inv_gloss = {v: k for k, v in self.gloss_vocab.items()}\n",
    "        \n",
    "    def _build_vocabs(self):\n",
    "        \n",
    "        text_words = []\n",
    "        gloss_words = []\n",
    "        \n",
    "        for _, row in self.df.iterrows():\n",
    "            \n",
    "            gloss = row['text'].split('[INST]')[1].split('[/INST]')[0].strip()\n",
    "            gloss_words.extend(gloss.split())\n",
    "            \n",
    "            text = row['text'].split('[/INST]')[1].replace('</s>', '').strip()\n",
    "            text_words.extend(text.lower().split())\n",
    "            \n",
    "            # build text vocab\n",
    "            text_counter = Counter(text_words)\n",
    "            for word, _ in text_counter.most_common():\n",
    "                if word not in self.text_vocab:\n",
    "                    self.text_vocab[word] = len(self.text_vocab)\n",
    "            \n",
    "            #build gloss vocab\n",
    "            gloss_counter = Counter(gloss_words)\n",
    "            for gloss, _ in gloss_counter.most_common():\n",
    "                if gloss not in self.gloss_vocab:\n",
    "                    self.gloss_vocab[gloss] = len(self.gloss_vocab)\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _process_sequence(self, sequence, vocab, is_gloss=False):\n",
    "        \n",
    "        if is_gloss:\n",
    "            seq = sequence.split('[INST]')[1].split('[/INST]')[0].strip().split()\n",
    "        else:\n",
    "            seq = sequence.split('[/INST]')[1].replace('</s>', '').strip().lower().split()\n",
    "        \n",
    "        indices = [vocab.get(word, vocab[\"<unk>\"]) for word in seq]\n",
    "        indices = [vocab[\"<sos>\"]] + indices + [vocab[\"<eos>\"]]\n",
    "        \n",
    "        if len(indices) < self.max_seq_length:\n",
    "            indices = indices + [vocab[\"<pad>\"]] * (self.max_seq_length - len(indices))\n",
    "        else:\n",
    "            indices = indices[:self.max_seq_length-1] + [vocab[\"<eos>\"]]\n",
    "        \n",
    "        return torch.tensor(indices).to(device)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]['text']\n",
    "        \n",
    "        gloss = self._process_sequence(row, self.gloss_vocab, is_gloss=True)\n",
    "        text = self._process_sequence(row, self.text_vocab, is_gloss=False)\n",
    "        \n",
    "        return text, gloss\n",
    "    \n",
    "    def decode_gloss(self, indices):\n",
    "        return ' '.join([self.inv_gloss.get(idx, '<unk>') for idx in indices if idx not in {0, 1, 2}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:52.168969500Z",
     "start_time": "2025-06-03T06:21:52.137493900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Text2GlossTransformer(nn.Module):\n",
    "    def __init__(self, text_vocab_size, gloss_vocab_size):\n",
    "        super().__init__()\n",
    "        self.text_embed = nn.Embedding(text_vocab_size, 256)\n",
    "        self.gloss_embed = nn.Embedding(gloss_vocab_size, 256)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=256, nhead=8, num_encoder_layers=3, num_decoder_layers=3\n",
    "        ).to(device)\n",
    "        self.fc = nn.Linear(256, gloss_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.text_embed(src).permute(1,0,2) # S, B, E\n",
    "        tgt = self.gloss_embed(tgt).permute(1,0,2)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(0)).to(device)\n",
    "        output = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        return self.fc(output).permute(1,0,2) # B, S, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gloss-to-Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:53.976701300Z",
     "start_time": "2025-06-03T06:21:53.965553Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Gloss2Pose(nn.Module):\n",
    "    def __init__(self, gloss_vocab_size, pose_dim=51): # 17 key points * 3 (x, y, conf)\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(gloss_vocab_size, 128)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Conv1d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, pose_dim, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, gloss_seq):\n",
    "        x = self.embed(gloss_seq).permute(0,2,1) # B, C, S\n",
    "        return self.conv(x).permute(0,2,1) # B, S, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:54.648783600Z",
     "start_time": "2025-06-03T06:21:54.624890Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def render_pose(pose, connections, frame_size=(512, 512)):\n",
    "    frame = np.zeros((*frame_size, 3), dtype=np.uint8)\n",
    "    keypoints = pose.reshape(-1,3)\n",
    "    keypoints[:, :2] = keypoints[:, :2] * frame_size[0]\n",
    "\n",
    "    # draw connections\n",
    "    for i, j in connections:\n",
    "        if keypoints[i, 2] > 0.2 and keypoints[j, 2] > 0.2: # conf thresh\n",
    "            cv2.line(\n",
    "                frame,\n",
    "                (int(keypoints[i,0]), int(keypoints[i, 1])),\n",
    "                (int(keypoints[j, 0]), int(keypoints[j, 1])),\n",
    "                (255, 166, 2), # orange\n",
    "                2\n",
    "            )\n",
    "\n",
    "\n",
    "    # draw points\n",
    "    for i, (x, y, conf) in enumerate(keypoints):\n",
    "        if conf > 0.2:\n",
    "            cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 255), -1) # yellow\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:58.588530Z",
     "start_time": "2025-06-03T06:21:55.297622900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahmi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "  3%|▎         | 1/30 [02:27<1:11:07, 147.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=1.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [04:53<1:08:28, 146.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=1.5963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:19<1:05:56, 146.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=1.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [10:11<1:07:47, 156.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [13:11<1:08:41, 164.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.8943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [16:12<1:08:11, 170.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [19:04<1:05:32, 170.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [21:46<1:01:40, 168.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.7741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [24:45<1:00:00, 171.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [27:42<57:42, 173.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [30:33<54:37, 172.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.3680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [33:31<52:13, 174.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [36:11<48:07, 169.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [38:40<43:36, 163.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [41:35<41:47, 167.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [44:37<40:01, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [47:42<38:04, 175.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [50:45<35:33, 177.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [53:46<32:46, 178.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [56:36<29:22, 176.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [59:08<25:18, 168.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss=0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [1:01:42<21:55, 164.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss=0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [1:04:43<19:45, 169.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss=0.0945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [1:07:41<17:12, 172.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss=0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [1:10:40<14:30, 174.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss=0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [1:13:37<11:39, 174.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss=0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [1:16:12<08:27, 169.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss=0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [1:18:45<05:27, 163.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss=0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [1:21:22<02:41, 161.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss=0.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:23:56<00:00, 167.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss=0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_index = train_index + 1\n",
    "\n",
    "dataset = TextGlossDataset2('../../datasets/train-00000-of-00001.parquet')\n",
    "\n",
    "t2g_model = Text2GlossTransformer(\n",
    "    len(dataset.text_vocab),\n",
    "    len(dataset.gloss_vocab)\n",
    ").to(device)\n",
    "\n",
    "g2p_model = Gloss2Pose(len(dataset.gloss_vocab)).to(device)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(t2g_model.parameters()) + list(g2p_model.parameters()),\n",
    "    lr = 1e-4\n",
    ")\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(30)):\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_input = torch.cat([\n",
    "            torch.ones_like(tgt[:, :1]) * dataset.gloss_vocab[\"<sos>\"],\n",
    "            tgt[:, :-1]\n",
    "        ], dim=1)\n",
    "\n",
    "        gloss_logits = t2g_model(src, decoder_input)\n",
    "        # gloss_loss = nn.CrossEntropyLoss()(\n",
    "        #     gloss_logits.view(-1, gloss_logits.size(-1)),\n",
    "        #     tgt.view(-1)\n",
    "        # )\n",
    "\n",
    "        gloss_logits = gloss_logits.contiguous()\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(\n",
    "            gloss_logits.view(-1, gloss_logits.size(-1)),\n",
    "            tgt.contiguous().view(-1)\n",
    "        )\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:22:02.943543300Z",
     "start_time": "2025-06-03T06:22:02.919435200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Loss' : losses\n",
    "})\n",
    "\n",
    "df.to_csv(f'train{train_index}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Sign testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:22:04.073494Z",
     "start_time": "2025-06-03T06:22:04.054671100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_sign(text):\n",
    "    tokens = [dataset.text_vocab.get(w, 0) for w in text.split()]\n",
    "    src_tokens = torch.tensor([tokens]).to(device)\n",
    "\n",
    "    gloss_seq = [dataset.gloss_vocab[\"<sos>\"]]\n",
    "    for i in tqdm.tqdm(range(20)):\n",
    "        gloss_decoder_input = torch.tensor([gloss_seq]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = t2g_model(src_tokens, gloss_decoder_input)\n",
    "        next_id = logits[0, -1].argmax().item()\n",
    "        if next_id == dataset.gloss_vocab[\"<eos>\"]:\n",
    "            break\n",
    "        gloss_seq.append(next_id)\n",
    "\n",
    "    glosses = [dataset.inv_gloss[idx] for idx in gloss_seq[1:]]\n",
    "    print(f\"Glosses: {' '.join(glosses)}\")\n",
    "\n",
    "    gloss_tensor = torch.tensor([gloss_seq[1:]]).to(device)  # Exclude <sos>\n",
    "    with torch.no_grad():\n",
    "        poses = g2p_model(gloss_tensor).cpu().numpy()[0]  # [S, D]\n",
    "\n",
    "    connections = [\n",
    "        (0,1), (0,2), (1,3), (2,4),        # Head\n",
    "        (5,6), (5,7), (7,9), (6,8), (8,10), # Arms\n",
    "        (11,12), (11,13), (13,15), (12,14), (14,16) # Legs\n",
    "    ]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(f'sign_output{train_index}.mp4', fourcc, 5.0, (512, 512))\n",
    "\n",
    "    for pose in poses:\n",
    "        pose_norm = (pose - np.min(pose)) / (np.max(pose) - np.min(pose) + 1e-8)\n",
    "        frame = render_pose(pose_norm, connections)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    return glosses, f'sign_output{train_index}.mp4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:22:06.505088900Z",
     "start_time": "2025-06-03T06:22:05.102502600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 48.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glosses: <sos> SON RETURN HOME, HOLD ROAD, THEN NOW GOURD LOWER VILLAGE, THEN NOW NOT THEN NOW GOURD FILL, NO LEAK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['<sos>',\n",
       "  'SON',\n",
       "  'RETURN',\n",
       "  'HOME,',\n",
       "  'HOLD',\n",
       "  'ROAD,',\n",
       "  'THEN',\n",
       "  'NOW',\n",
       "  'GOURD',\n",
       "  'LOWER',\n",
       "  'VILLAGE,',\n",
       "  'THEN',\n",
       "  'NOW',\n",
       "  'NOT',\n",
       "  'THEN',\n",
       "  'NOW',\n",
       "  'GOURD',\n",
       "  'FILL,',\n",
       "  'NO',\n",
       "  'LEAK.'],\n",
       " 'sign_output739415.mp4')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sign(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T06:21:15.809143300Z",
     "start_time": "2025-06-03T06:21:15.797312200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
